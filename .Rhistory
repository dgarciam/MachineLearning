full_data$Aviso
full_data2 = subset(full_data, Aviso != '')
View(full_data2)
file = "C:/Users/Dan Garcia/Box Sync/Correctivos Thales-Sofratesa/08 CORRECTIVO AGOSTO 2015.xlsx"
full_data = read.xlsx2(file, sheetIndex = 1)
full_data = subset(full_data, Aviso != '')
full_data2 = read.xlsx2(file, sheetIndex = 2)
View(full_data2)
full_data2 = subset(full_data2, Aviso != '')
full_data3 = read.xlsx2(file, sheetIndex = 3)
remove(full_data3)
View(full_data)
full_data3 = read.xlsx(file, sheetIndex = 2)
View(full_data3)
full_data4 = read.xlsx(file, sheetIndex =1)
View(full_data4)
remove(full_data4)
summary(lm(count ~spray, data = InsectSprays))
summary(lm(count ~spray, data = InsectSprays))$coef
summary(lm(count ~spray, data = InsectSprays))$sigma
InsectSprays
plot(InsectSprays)
summary(lm(count ~spray, data = InsectSprays))$coef
summary(lm(count ~spray -1, data = InsectSprays))$coef
library(ggplot2)
mtcards
mtcars
autos = mtcars
names(mtcars)
names(autos)
autos
autos
names(autos)
names$mpg
autos$mpg
autos$names
autos[1]
autos
?mtcars
mecanico = subset(mtcars, am == 1)
automatica = subset(mtcars, am == 0)
mecanico
remove(autos)
automatic = subset(mtcars, am == 0)
mechanic = subset(mtcars, am == 1)
remove(automatica, mecanico)
mechanic
automatic
plot(mechanic, automatic)
plot(mechanic$mpg, automatic$mpg)
plot(mechanic$mpg)
plot(mechanic$mpg ~ automatic$mpg)
plot(mtcars$mpg, mtcars$am)
plot(mtcars$am, mtcars$mpg)
plot(as.factor(mtcars$am), mtcars$mpg)
mean(automatic$mpg)
mean(mechanic$mpg)
mean(mechanic$mpg);mean(automatic$mpg)
plot(mtcars$am, mtcars$mpg)
plot(as.factor(mtcars$am), mtcars$mpg)
mean(mechanic$mpg) - mean(automatic$mpg)
summary(mechanic)
summary(mechanic$mpg)$mean
test = summary(mechanic$mpg)
test
test$Mean
test$Median
test
?test
test
test$Median
test$median
remove(test)
mean(mechanic$mpg)
mean(automatic$mpg)
plot(as.factor(mtcars$am), mtcars$mpg,xlab = "Transmission (0 = automatic, 1 = manual)")
?t.test
t.test(mpg ~ am)$p.value
attach(mtcars)
t.test(mpg ~ am)$p.value
t.test(mpg ~ am)$estimate
plot(as.factor(mtcars$am), mtcars$mpg,ylab = "MPG", xlab = "Transmission (0 = automatic, 1 = manual)")
plot(as.factor(mtcars$am), mtcars$mpg,main = "MPG by Transmission", ylab = "MPG", xlab = "Transmission (0 = automatic, 1 = manual)")
plot(as.factor(mtcars$am), mtcars$mpg,main = "MPG vs.Transmission Type", ylab = "MPG", xlab = "Transmission (0 = automatic, 1 = manual)")
mean(mechanic$mpg)
t.test(mpg ~ . )$p.value
t.test(mpg ~ am )$p.value
version
install.packages("doParallel")
library(doParallel)
install.packages("installr") # install
installr::updateR() # updating R.
version
library(doParallel)
install.packages(c("base64enc", "chron", "curl", "e1071", "evaluate", "ggthemes", "git2r", "gridExtra", "httpuv", "knitr", "maps", "openxlsx", "PKI", "psych", "R6", "RandomFields", "raster", "Rcpp", "rgdal", "rJava", "rversions", "shiny", "stargazer", "stringi", "XML"))
library(ggplot2)
mechanic = subset(mtcars, am == 1)
automatic = subset(mtcars, am == 0)
plot(as.factor(mtcars$am), mtcars$mpg,main = "MPG vs.Transmission Type", ylab = "MPG", xlab = "Transmission (0 = automatic, 1 = manual)")
mean(mechanic$mpg)
mean(automatic$mpg)
meanDifference = mean(mechanic$mpg) - mean(automatic$mpg)
factor(mtcars$cyl)
mtcars$cyl
lm(mpg ~ ., data = mtcars)
step(full.model, direction = "backward")
full.model <- lm(mpg ~ ., data = mtcars)
best.model <- step(full.model, direction = "backward")
summary(best.model)
plot(best.model)
par(mfrow=c(2,2))
plot(best.model)
boxplot(mpg ~ am, data = mtcars, col = "blue", ylab = "miles per gallon")
par(mfrow=c(3,2))
plot(best.model)
boxplot(mpg ~ am, data = mtcars, col = "blue", ylab = "miles per gallon")
par(mfrow=c(2,2))
plot(best.model)
?aov
?xtable
?xtabs
mtcars
xtabs(mtcars)
library("knitr", lib.loc="~/R/win-library/3.2")
library(efc)
install.packages("efc")
install.packages("sjPlot")
library(sjPlot)
sjt.df(mtcars)
mtcars
test = mtcars
test
remove(test)
kable(mtcars)
Variable = c(mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb)
Variable = c("mpg", "cyl", "disp", "hp", "drat", "wt", "qsec", "vs", "am", "gear", "carb")
Description = c("Miles/(US) gallon", "Number of cylinders", "Displacement (cu.in.)","Gross HorsePower", "Rear Axle Ratio", "Weight (lb/1000)",
"1/4 mile time", "V/S", "Transmission (0 = automatic, 1 = manual)", "Number of Forward Gears", "Number of Carburetors")
tabla = merge(Variable, Description)
tabla
tabla = cbind(Variable, Description)
tabla
kable(tabla)
swirl()
library(swirl)
ls()
swirl()
simbias()
x1c <- simbias()
apply(x1c, 1, mean)
anova()asd
anova(as)
x1hist()
fit1 <- x1hist
swirl()
fit1 <- anova(fertility)
fit1 <- anova()
fit1 <- test
fit1 <- tabla
swirl()
bogus()
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- deviance(fit1)-deviance(fit3)
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
lm(child ~ parent, galton)
fit <- lm(child ~ parent, galton)
fit$residuals/n-2
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit$sigma)
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
galton$child
mu <- mean(galton$child)
sTot <- mean(galton$child)
sTot <- sum((galton$child-mu)^2)
sRes <-
sRes <-
sRes <-
)
sRes <- galton$child
sRes <- deviance(fit)
1 - sRES/sTot
1 - sRes/sTot
summary(fit)$r
summary(fit)$r.squared
cor(galton$child,galton$parent)
cor(galton$parent,galton$child)^2
out2
fit <- lm(y ~ x, out2)
plot(fit, which=1)
fitno <- lm(y ~x, out2[-1,])
plot(fitno, which=1)
coef(fit) - coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma <- r2-r
sigma <- rss
sigma <- fit(resno)
sigma <- lm(resno)
sigma <- lm(resno ~ n)
sigma <- sqrt(deviance(fit)/df.residual(fit))
sigma*sqrt(1-hatvalues(fit))
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1 <- fitno
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
sqrt(1-hatvalues(fit)[1])
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
predict(fitno, out2) - predict(fit, out2)
dy <- predict(fitno, out2)-predict(fit, out2)
dy / 2*sigma^2
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
library(shiny)
install.packages("boxr")
library(boxr)
box_auth()
?download.file
box_auth()
print(self$endpoint)
box_auth()
print(self$endpoint)
install.packages("slidify")
install.packages("Rpresenter")
library(Rpresenter)
install.packages("slidify")
library(shiny)
runExample("01_hello")
runApp("my_app")
runApp("App-1")
runApp("App-1", display.mode = "showcase")
shiny::runApp('App-1')
library(plyr) ## Libreria a usar para el cambio de nombre de columnas
library(lubridate) ##Manejo de Fechas
#library(xlsx) ## Libreria a usar para la escritura de archivo excel
library(XLConnect)
condicion = "HUM"
patron = paste0(condicion,"*.*.csv")
EndDirectory = getwd()
StartDirectory = "C:/Users/Dan Garcia/ownCloud/Panama/14 - Reportes/06 - Temperatura/2015/08 - Agosto"
#StartDirectory =
setwd(StartDirectory)
directorio = list.files(pattern=patron)
start_date = "2015/08/01"
end_date = "2015/08/31"
full_data = c()
for (file in seq_along(directorio)){
data = read.csv(directorio[file],skip=19)                ## Los headers de las columnas estan en la linea #20
station = substr(directorio[file],start = 1, stop = 3)   ##Extrae el nombre de la estación del FileName
data$station = station              ## Añade una columna de estacion con el nombre de la estacion procesandose
full_data = rbind(full_data,data)   ##Acumula la data de manera general
}
#remove(data, station, patron, file, directorio)
full_data$Date = as.Date(full_data$Date.Time,format = "%m/%d/%y") ## Crea Columna Fecha
full_data$Time = sapply(strsplit(as.character(full_data$Date.Time), " "), "[", 2)  ## Crea columna Hora
full_data = full_data[c(1,5,6,3,2,4)] ##Reordena las columnas
full_data = rename(full_data,c("Value"=condicion,"station"="Estacion","Date.Time" = "Fecha")) ##Renombra dos columnas
full_data = subset(full_data,Date >= start_date & Date <= end_date) ##Filtra por las fechas requeridas
full_data$Fecha = mdy_hms(full_data$Fecha)
full_data = arrange(full_data, Estacion, Fecha)
## Determinar un incremento de mas de 3 grados por hora por estacion
estaciones = unique(full_data$Estacion)
tabla_diferencias = c()
variacion_maxima = 11
for (est in seq_along(estaciones)){
bloque = subset(full_data,Estacion == estaciones[est])
for (row in 5:nrow(bloque)){
est2 = bloque[row,]
est1 = bloque[row - 4,]
diferencia_temp = est2$HUM - est1$HUM
if (abs(diferencia_temp) > variacion_maxima) {
tabla_diferencias = rbind(tabla_diferencias, est1, est2)
}
}
}
full_data$Fecha = as.character(full_data$Fecha)
full_data$Date = as.character(full_data$Date)
tabla_diferencias$Fecha = as.character(tabla_diferencias$Fecha)
tabla_diferencias$Date = as.character(tabla_diferencias$Date)
writeWorksheetToFile("Reporte.Ambiental.xlsx", data=list(i1 = full_data, i2 = tabla_diferencias), sheet = c(condicion, "Variacion_HUM"))
#write.xlsx(full_data, "Reporte.Ambiental.xlsx", sheetName = condicion, row.names = FALSE, append=TRUE) ##Escribe Tabla Final en Excel
#write.xlsx(tabla_diferencias, "Reporte.Ambiental.xlsx", sheetName = "Variacion_TEM", row.names = FALSE, append = TRUE)
setwd(EndDirectory)
}
install.packages("caret")
library(caret)
precios = c(775,625,733,929,895,749,1020,1349,599,1143,1209,1495,879,975,1076,1282,665,705,799,500)
hist(precios)
median(precios)
mean(precios)
summary(precios)
install.packages("ISLR")
library(ISLR)
library(ggplot2)
library(caret)
data("Wage")
summary(Wage)
hist(Wage)
hist(Wage$year)
hist(Wage$race)
hist(Wage$age)
plot(Wage)
plot(Wage$year, Wage$age)
plot(Wage$year, Wage$age, type = "l")
plot(Wage$year, Wage$age)
plot(Wage$sex)
plot(Wage$sex,Wage$maritl)
plot(Wage$race,Wage$maritl)
plot(Wage$age,Wage$wage)
table(Wave$jobclass)
table(Wage$jobclass)
Wage$jobclass
table(Wage$jobclass)
?dummyVars
install.packages("kernlab")
a
library(caret)
library(kernlab)
data(spam)
library(caret)
library(kernlab)
data(spam)
inTrain = createDataPartition(y=spam$type, p=0.75, list=FALSE)
training = spam[inTrain,]
testing = spam[-intrain,]
testing = spam[-inTrain,]
View(training)
ncol(training)
nrow(training)
M = abs(cor(training[,58]))
M = abs(cor(training[,-58]))
View(M)
?diag
diag(M) = 0
View(M)
M = abs(cor(training[,-58]))
View(M)
diag(M) = 0
which(M > 0.8, arr.ind = T)
names(spam)[c32,31]
names(spam)[c(32,31)]
names(spam)[c(32,34)]
plot(spam[,34])
plot(spam[,34],spam[,32])
plot(spam[,34],spam[,31])
plot(spam[,40],spam[,34])
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
library(ggplot2)
library(rattle)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,data = training, method = "rpart")
fancyRpartPlot(model$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(model$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
#(NOTE: If you have trouble installing the pgmm package, you can download the olive dataset here: olive_data.zip. After unzipping the archive, you can load the file using the load() function in R.)
#These data contain information on 572 different Italian olive oils from multiple regions in Italy. Fit a classification tree where Area is the outcome variable. Then predict the value of area for the following data frame using the tree command with all defaults
newdata = as.data.frame(t(colMeans(olive)))
library(pgmm)
data(olive)
olive = olive[,-1]
#(NOTE: If you have trouble installing the pgmm package, you can download the olive dataset here: olive_data.zip. After unzipping the archive, you can load the file using the load() function in R.)
#These data contain information on 572 different Italian olive oils from multiple regions in Italy. Fit a classification tree where Area is the outcome variable. Then predict the value of area for the following data frame using the tree command with all defaults
newdata = as.data.frame(t(colMeans(olive)))
View(newdata)
View(newdata)
model<-train(Area ~ ., data=olive, method="rpart")
predict(model, newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
model = train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
str(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
vowel.rfmodel <- train(y ~ ., data=vowel.train, method="rf")
str(vowel.train)
str(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
vowel.rfmodel <- train(y ~ ., data=vowel.train, method="rf")
varImp(vowel.rfmodel)
install.packages("c("gbm", "e1071")")
install.packages(c("gbm", "e1071"))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
install.packages(c("car", "curl", "devtools", "dplyr", "evaluate", "formatR", "gstat", "highr", "Hmisc", "installr", "intervals", "jsonlite", "lme4", "MatrixModels", "mime", "psych", "quantreg", "raster", "Rcpp", "RcppEigen", "rgdal", "rmarkdown", "RSAGA", "scales", "sjmisc", "sjPlot", "sp", "tidyr", "xml2"))
install.packages("gputools")
install.packages("gputools")
install.packages("gputools")
install.packages(c("coda", "SparseM"))
?coda
library(coda)
?coda
install.packages("gmatrix")
install.packages("Rth")
install.packages("C:/Users/Dan Garcia/Downloads/rpux_0.5.2_win.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Dan Garcia/Downloads/rpud/rpud_0.5.2.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Dan Garcia/Downloads/rpud/rpudplus_0.5.2.zip", repos = NULL, type = "win.binary")
Sys.getenv("HOME")
library(caret)
library(doParallel)
set.seed(1234556) #Give it to me baby, aha, aha!
directory = "C:/Users/Dan Garcia/Dropbox/Tareas/tarea/MachineLearning/project"
setwd(directory)
training = read.csv("pml-training.csv")
testing = read.csv("pml-testing.csv")
training = training[,!grepl("^X|window|timestamp|user_name", names(training))] #Removing Columns
training = training[, colSums(is.na(training)) < (nrow(training)/2)] #Remove Columns With NAs > 50%
inTrain = createDataPartition(y=training$classe, p=0.70, list=FALSE)
training.set = training[inTrain,]
testing.set = training[-inTrain,]
cl <- makeCluster(detectCores())
registerDoParallel(cl)
inicio = Sys.time()
randomForest.model = train(classe ~ .,
data=training.set,
method="rf",
importance= TRUE,
trControl = trainControl(method = "cv", 10)
do.trace = TRUE
)
fin = Sys.time()
tiempo = fin - inicio
stopCluster(cl)
library(caret)
library(doParallel)
set.seed(1234556) #Give it to me baby, aha, aha!
directory = "C:/Users/Dan Garcia/Dropbox/Tareas/tarea/MachineLearning/project"
setwd(directory)
training = read.csv("pml-training.csv")
testing = read.csv("pml-testing.csv")
training = training[,!grepl("^X|window|timestamp|user_name", names(training))] #Removing Columns
training = training[, colSums(is.na(training)) < (nrow(training)/2)] #Remove Columns With NAs > 50%
inTrain = createDataPartition(y=training$classe, p=0.70, list=FALSE)
training.set = training[inTrain,]
testing.set = training[-inTrain,]
cl <- makeCluster(detectCores())
registerDoParallel(cl)
inicio = Sys.time()
randomForest.model = train(classe ~ .,
data=training.set,
method="rf",
importance= TRUE,
trControl = trainControl(method = "cv", 10),
do.trace = TRUE
)
library(caret)
library(doParallel)
set.seed(1234556) #Give it to me baby, aha, aha!
directory = "C:/Users/Dan Garcia/Dropbox/Tareas/tarea/MachineLearning/project"
setwd(directory)
training = read.csv("pml-training.csv")
testing = read.csv("pml-testing.csv")
training = training[,!grepl("^X|window|timestamp|user_name", names(training))] #Removing Columns
training = training[, colSums(is.na(training)) < (nrow(training)/2)] #Remove Columns With NAs > 50%
inTrain = createDataPartition(y=training$classe, p=0.70, list=FALSE)
training.set = training[inTrain,]
testing.set = training[-inTrain,]
cl <- makeCluster(3)
registerDoParallel(cl)
inicio = Sys.time()
randomForest.model = train(classe ~ .,
data=training.set,
method="rf",
importance= TRUE,
trControl = trainControl(method = "cv", 10),
do.trace = TRUE
)
