meanDifference = mean(mechanic$mpg) - mean(automatic$mpg)
factor(mtcars$cyl)
mtcars$cyl
lm(mpg ~ ., data = mtcars)
step(full.model, direction = "backward")
full.model <- lm(mpg ~ ., data = mtcars)
best.model <- step(full.model, direction = "backward")
summary(best.model)
plot(best.model)
par(mfrow=c(2,2))
plot(best.model)
boxplot(mpg ~ am, data = mtcars, col = "blue", ylab = "miles per gallon")
par(mfrow=c(3,2))
plot(best.model)
boxplot(mpg ~ am, data = mtcars, col = "blue", ylab = "miles per gallon")
par(mfrow=c(2,2))
plot(best.model)
?aov
?xtable
?xtabs
mtcars
xtabs(mtcars)
library("knitr", lib.loc="~/R/win-library/3.2")
library(efc)
install.packages("efc")
install.packages("sjPlot")
library(sjPlot)
sjt.df(mtcars)
mtcars
test = mtcars
test
remove(test)
kable(mtcars)
Variable = c(mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb)
Variable = c("mpg", "cyl", "disp", "hp", "drat", "wt", "qsec", "vs", "am", "gear", "carb")
Description = c("Miles/(US) gallon", "Number of cylinders", "Displacement (cu.in.)","Gross HorsePower", "Rear Axle Ratio", "Weight (lb/1000)",
"1/4 mile time", "V/S", "Transmission (0 = automatic, 1 = manual)", "Number of Forward Gears", "Number of Carburetors")
tabla = merge(Variable, Description)
tabla
tabla = cbind(Variable, Description)
tabla
kable(tabla)
swirl()
library(swirl)
ls()
swirl()
simbias()
x1c <- simbias()
apply(x1c, 1, mean)
anova()asd
anova(as)
x1hist()
fit1 <- x1hist
swirl()
fit1 <- anova(fertility)
fit1 <- anova()
fit1 <- test
fit1 <- tabla
swirl()
bogus()
fit1 <- lm(Fertility ~ Agriculture, swiss)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education)
fit3 <- lm(Fertility ~ Agriculture + Examination + Education, swiss)
anova(fit1, fit3)
deviance(fit3)
d <- deviance(fit3)/43
n <- deviance(fit1)-deviance(fit3)
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
lm(child ~ parent, galton)
fit <- lm(child ~ parent, galton)
fit$residuals/n-2
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit$sigma)
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
galton$child
mu <- mean(galton$child)
sTot <- mean(galton$child)
sTot <- sum((galton$child-mu)^2)
sRes <-
sRes <-
sRes <-
)
sRes <- galton$child
sRes <- deviance(fit)
1 - sRES/sTot
1 - sRes/sTot
summary(fit)$r
summary(fit)$r.squared
cor(galton$child,galton$parent)
cor(galton$parent,galton$child)^2
out2
fit <- lm(y ~ x, out2)
plot(fit, which=1)
fitno <- lm(y ~x, out2[-1,])
plot(fitno, which=1)
coef(fit) - coef(fitno)
head(dfbeta(fit))
resno <- out2[1, "y"] - predict(fitno, out2[1,])
1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma <- r2-r
sigma <- rss
sigma <- fit(resno)
sigma <- lm(resno)
sigma <- lm(resno ~ n)
sigma <- sqrt(deviance(fit)/df.residual(fit))
sigma*sqrt(1-hatvalues(fit))
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1 <- fitno
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
sqrt(1-hatvalues(fit)[1])
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
predict(fitno, out2) - predict(fit, out2)
dy <- predict(fitno, out2)-predict(fit, out2)
dy / 2*sigma^2
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
library(shiny)
install.packages("boxr")
library(boxr)
box_auth()
?download.file
box_auth()
print(self$endpoint)
box_auth()
print(self$endpoint)
install.packages("slidify")
install.packages("Rpresenter")
library(Rpresenter)
install.packages("slidify")
library(shiny)
runExample("01_hello")
runApp("my_app")
runApp("App-1")
runApp("App-1", display.mode = "showcase")
shiny::runApp('App-1')
library(plyr) ## Libreria a usar para el cambio de nombre de columnas
library(lubridate) ##Manejo de Fechas
#library(xlsx) ## Libreria a usar para la escritura de archivo excel
library(XLConnect)
condicion = "HUM"
patron = paste0(condicion,"*.*.csv")
EndDirectory = getwd()
StartDirectory = "C:/Users/Dan Garcia/ownCloud/Panama/14 - Reportes/06 - Temperatura/2015/08 - Agosto"
#StartDirectory =
setwd(StartDirectory)
directorio = list.files(pattern=patron)
start_date = "2015/08/01"
end_date = "2015/08/31"
full_data = c()
for (file in seq_along(directorio)){
data = read.csv(directorio[file],skip=19)                ## Los headers de las columnas estan en la linea #20
station = substr(directorio[file],start = 1, stop = 3)   ##Extrae el nombre de la estación del FileName
data$station = station              ## Añade una columna de estacion con el nombre de la estacion procesandose
full_data = rbind(full_data,data)   ##Acumula la data de manera general
}
#remove(data, station, patron, file, directorio)
full_data$Date = as.Date(full_data$Date.Time,format = "%m/%d/%y") ## Crea Columna Fecha
full_data$Time = sapply(strsplit(as.character(full_data$Date.Time), " "), "[", 2)  ## Crea columna Hora
full_data = full_data[c(1,5,6,3,2,4)] ##Reordena las columnas
full_data = rename(full_data,c("Value"=condicion,"station"="Estacion","Date.Time" = "Fecha")) ##Renombra dos columnas
full_data = subset(full_data,Date >= start_date & Date <= end_date) ##Filtra por las fechas requeridas
full_data$Fecha = mdy_hms(full_data$Fecha)
full_data = arrange(full_data, Estacion, Fecha)
## Determinar un incremento de mas de 3 grados por hora por estacion
estaciones = unique(full_data$Estacion)
tabla_diferencias = c()
variacion_maxima = 11
for (est in seq_along(estaciones)){
bloque = subset(full_data,Estacion == estaciones[est])
for (row in 5:nrow(bloque)){
est2 = bloque[row,]
est1 = bloque[row - 4,]
diferencia_temp = est2$HUM - est1$HUM
if (abs(diferencia_temp) > variacion_maxima) {
tabla_diferencias = rbind(tabla_diferencias, est1, est2)
}
}
}
full_data$Fecha = as.character(full_data$Fecha)
full_data$Date = as.character(full_data$Date)
tabla_diferencias$Fecha = as.character(tabla_diferencias$Fecha)
tabla_diferencias$Date = as.character(tabla_diferencias$Date)
writeWorksheetToFile("Reporte.Ambiental.xlsx", data=list(i1 = full_data, i2 = tabla_diferencias), sheet = c(condicion, "Variacion_HUM"))
#write.xlsx(full_data, "Reporte.Ambiental.xlsx", sheetName = condicion, row.names = FALSE, append=TRUE) ##Escribe Tabla Final en Excel
#write.xlsx(tabla_diferencias, "Reporte.Ambiental.xlsx", sheetName = "Variacion_TEM", row.names = FALSE, append = TRUE)
setwd(EndDirectory)
}
install.packages("caret")
library(caret)
precios = c(775,625,733,929,895,749,1020,1349,599,1143,1209,1495,879,975,1076,1282,665,705,799,500)
hist(precios)
median(precios)
mean(precios)
summary(precios)
install.packages("ISLR")
library(ISLR)
library(ggplot2)
library(caret)
data("Wage")
summary(Wage)
hist(Wage)
hist(Wage$year)
hist(Wage$race)
hist(Wage$age)
plot(Wage)
plot(Wage$year, Wage$age)
plot(Wage$year, Wage$age, type = "l")
plot(Wage$year, Wage$age)
plot(Wage$sex)
plot(Wage$sex,Wage$maritl)
plot(Wage$race,Wage$maritl)
plot(Wage$age,Wage$wage)
table(Wave$jobclass)
table(Wage$jobclass)
Wage$jobclass
table(Wage$jobclass)
?dummyVars
install.packages("kernlab")
a
library(caret)
library(kernlab)
data(spam)
library(caret)
library(kernlab)
data(spam)
inTrain = createDataPartition(y=spam$type, p=0.75, list=FALSE)
training = spam[inTrain,]
testing = spam[-intrain,]
testing = spam[-inTrain,]
View(training)
ncol(training)
nrow(training)
M = abs(cor(training[,58]))
M = abs(cor(training[,-58]))
View(M)
?diag
diag(M) = 0
View(M)
M = abs(cor(training[,-58]))
View(M)
diag(M) = 0
which(M > 0.8, arr.ind = T)
names(spam)[c32,31]
names(spam)[c(32,31)]
names(spam)[c(32,34)]
plot(spam[,34])
plot(spam[,34],spam[,32])
plot(spam[,34],spam[,31])
plot(spam[,40],spam[,34])
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
library(ggplot2)
library(rattle)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,data = training, method = "rpart")
fancyRpartPlot(model$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(model$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
#(NOTE: If you have trouble installing the pgmm package, you can download the olive dataset here: olive_data.zip. After unzipping the archive, you can load the file using the load() function in R.)
#These data contain information on 572 different Italian olive oils from multiple regions in Italy. Fit a classification tree where Area is the outcome variable. Then predict the value of area for the following data frame using the tree command with all defaults
newdata = as.data.frame(t(colMeans(olive)))
library(pgmm)
data(olive)
olive = olive[,-1]
#(NOTE: If you have trouble installing the pgmm package, you can download the olive dataset here: olive_data.zip. After unzipping the archive, you can load the file using the load() function in R.)
#These data contain information on 572 different Italian olive oils from multiple regions in Italy. Fit a classification tree where Area is the outcome variable. Then predict the value of area for the following data frame using the tree command with all defaults
newdata = as.data.frame(t(colMeans(olive)))
View(newdata)
View(newdata)
model<-train(Area ~ ., data=olive, method="rpart")
predict(model, newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
model = train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
missClass(testSA$chd, predict(model, testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
str(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
vowel.rfmodel <- train(y ~ ., data=vowel.train, method="rf")
str(vowel.train)
str(vowel.test)
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
vowel.rfmodel <- train(y ~ ., data=vowel.train, method="rf")
varImp(vowel.rfmodel)
install.packages("c("gbm", "e1071")")
install.packages(c("gbm", "e1071"))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
install.packages(c("car", "curl", "devtools", "dplyr", "evaluate", "formatR", "gstat", "highr", "Hmisc", "installr", "intervals", "jsonlite", "lme4", "MatrixModels", "mime", "psych", "quantreg", "raster", "Rcpp", "RcppEigen", "rgdal", "rmarkdown", "RSAGA", "scales", "sjmisc", "sjPlot", "sp", "tidyr", "xml2"))
library(caret)
library(doParallel)
set.seed(1234556) #Give it to me baby, aha, aha!
directory = "C:/Users/Dan Garcia/Dropbox/Tareas/tarea/MachineLearning/project"
setwd(directory)
training = read.csv("pml-training.csv")
testing = read.csv("pml-testing.csv")
training = training[,!grepl("^X|window|timestamp|user_name", names(training))] #Removing Columns
training = training[, colSums(is.na(training)) < (nrow(training)/2)] #Remove Columns With NAs > 50%
inTrain = createDataPartition(y=training$classe, p=0.70, list=FALSE)
training.set = training[inTrain,]
testing.set = training[-inTrain,]
randomForest.model <- readRDS("randomForest-final-model.rds")
randomForest.test = predict(randomForest.model, newdata = testing)
randomForest.predict.train <- predict(randomForest.model, newdata = training.set)
randomForest.train.confusionMatrix = confusionMatrix(data=randomForest.predict.train,  training.set$classe)
randomForest.train.confusionMatrix$overall
randomForest.train.performance  = data.frame(model = "Training set",
accuracy = randomForest.train.confusionMatrix$overall[1],
accuracyLower = randomForest.train.confusionMatrix$overall[3],
accuracyUpper = randomForest.train.confusionMatrix$overall[4])
randomForest.train.performance
randomForest.predict.test = predict(randomForest.model, newdata = testing.set)
randomForest.test.confusionMatrix = confusionMatrix(data=randomForest.predict.test,  testing.set$classe)
randomForest.test.confusionMatrix$overall
kable(randomForest.test.confusionMatrix$table)
library(knitr)
kable(randomForest.test.confusionMatrix$table)
library(caret)
library(doParallel)
library(knitr)
library(dplyr)
library(rpart)
library(kernlab)
library(reshape2)
set.seed(1234556) #Give it to me baby, aha, aha!
directory = "C:/Users/Dan Garcia/Dropbox/Tareas/tarea/MachineLearning/project"
setwd(directory)
testing = read.csv("pml-testing.csv")
testing = testing[,!grepl("^X|window|timestamp|user_name", names(testing))] #Removing Columns
testing = testing[, colSums(is.na(testing)) < (nrow(testing)/2)] #Remove Columns With NAs > 50%
randomForest.model = readRDS("randomForest-final-model.rds")
randomForest.test = predict(randomForest.model, newdata = testing)
# Coursera Submission
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
answers = randomForest.test
pml_write_files(answers)
library(caret)
library(doParallel)
library(knitr)
set.seed(1234556) #Give it to me baby, aha, aha!
directory = "C:/Users/Dan Garcia/Dropbox/Tareas/tarea/MachineLearning/project"
setwd(directory)
training = read.csv("pml-training.csv")
testing = read.csv("pml-testing.csv")
training = training[,!grepl("^X|window|timestamp|user_name", names(training))] #Removing Columns
training = training[, colSums(is.na(training)) < (nrow(training)/2)] #Remove Columns With NAs > 50%
inTrain = createDataPartition(y=training$classe, p=0.70, list=FALSE)
training.set = training[inTrain,]
testing.set = training[-inTrain,]
#cl <- makeCluster(3)
#registerDoParallel(cl)
#inicio = Sys.time()
#randomForest.model = train(classe ~ .,
#                            data=training.set,
#                            method="rf",
#                            importance= TRUE,
#                            trControl = trainControl(method = "cv", 10),
#                            do.trace = TRUE
#                            )
#fin = Sys.time()
#tiempo = fin - inicio
#stopCluster(cl)
randomForest.model = readRDS("randomForest-final-model.rds")
randomForest.predict.train <- predict(randomForest.model, newdata = training.set)
randomForest.train.confusionMatrix = confusionMatrix(data=randomForest.predict.train,  training.set$classe)
randomForest.train.confusionMatrix$overall
randomForest.train.performance  = data.frame(model = "Training set",
accuracy = randomForest.train.confusionMatrix$overall[1],
accuracyLower = randomForest.train.confusionMatrix$overall[3],
accuracyUpper = randomForest.train.confusionMatrix$overall[4])
randomForest.predict.test = predict(randomForest.model, newdata = testing.set)
randomForest.test.confusionMatrix = confusionMatrix(data=randomForest.predict.test,  testing.set$classe)
randomForest.test.confusionMatrix$overall
kable(randomForest.test.confusionMatrix$table)
saveRDS(randomForest.model, file = "randomForestSaved.rds")
library(caret)
library(doParallel)
library(knitr)
set.seed(1234556) #Give it to me baby, aha, aha!
directory = "C:/Users/Dan Garcia/Dropbox/Tareas/tarea/MachineLearning/project"
setwd(directory)
training = read.csv("pml-training.csv")
testing = read.csv("pml-testing.csv")
training = training[,!grepl("^X|window|timestamp|user_name", names(training))] #Removing Columns
training = training[, colSums(is.na(training)) < (nrow(training)/2)] #Remove Columns With NAs > 50%
inTrain = createDataPartition(y=training$classe, p=0.70, list=FALSE)
training.set = training[inTrain,]
testing.set = training[-inTrain,]
cl <- makeCluster(3)
registerDoParallel(cl)
inicio = Sys.time()
randomForest.model = train(classe ~ .,
data=training.set,
method="rf",
importance= TRUE,
trControl = trainControl(method = "none"),
do.trace = TRUE
)
fin = Sys.time()
tiempo = fin - inicio
stopCluster(cl)
cl <- makeCluster(3)
registerDoParallel(cl)
inicio = Sys.time()
randomForest.model = train(classe ~ .,
data=training.set,
method="rf",
importance= TRUE,
do.trace = TRUE
)
kable(rF.test.cfMatrix$table)
library(caret)
library(doParallel)
library(knitr)
set.seed(1234556) #Give it to me baby, aha, aha!
directory = "C:/Users/Dan Garcia/Dropbox/Tareas/tarea/MachineLearning/project"
setwd(directory)
training = read.csv("pml-training.csv")
testing = read.csv("pml-testing.csv")
training = training[,!grepl("^X|new_window|timestamp|user_name", names(training))] #Removing Columns
training = training[, colSums(is.na(training)) < (nrow(training)/2)] #Remove Columns With NAs > 50%
inTrain = createDataPartition(y=training$classe, p=0.70, list=FALSE)
training.set = training[inTrain,]
testing.set = training[-inTrain,]
set.seed(1234556) #Give it to me baby, aha, aha!
directory = "C:/Users/Dan Garcia/Dropbox/Tareas/tarea/MachineLearning/project"
setwd(directory)
training = read.csv("pml-training.csv")
testing = read.csv("pml-testing.csv")
training = training[,!grepl("X|new_window|timestamp|user_name", names(training))] #Removing Columns
training = training[, colSums(is.na(training)) < (nrow(training)/2)] #Remove Columns With NAs > 50%
inTrain = createDataPartition(y=training$classe, p=0.70, list=FALSE)
training.set = training[inTrain,]
testing.set = training[-inTrain,]
library(caret)
library(doParallel)
library(knitr)
set.seed(1234556) #Give it to me baby, aha, aha!
directory = "C:/Users/Dan Garcia/Dropbox/Tareas/tarea/MachineLearning/project"
setwd(directory)
training = read.csv("pml-training.csv")
testing = read.csv("pml-testing.csv")
training = training[,!grepl("timestamp|X|user_name|new_window", names(training))]
#training = training[,!grepl("X|new_window|timestamp|user_name", names(training))] #Removing Columns
training = training[, colSums(is.na(training)) < (nrow(training)/2)] #Remove Columns With NAs > 50%
inTrain = createDataPartition(y=training$classe, p=0.70, list=FALSE)
training.set = training[inTrain,]
testing.set = training[-inTrain,]
set.seed(1234556) #Give it to me baby, aha, aha!
directory = "C:/Users/Dan Garcia/Dropbox/Tareas/tarea/MachineLearning/project"
setwd(directory)
training = read.csv("pml-training.csv")
testing = read.csv("pml-testing.csv")
training = training[,!grepl("timestamp|X|user_name|new_window", names(training))]
#training = training[,!grepl("X|new_window|timestamp|user_name", names(training))] #Removing Columns
training = training[, colSums(is.na(training)) == 0] #Remove Columns With NAs > 50%
inTrain = createDataPartition(y=training$classe, p=0.70, list=FALSE)
training.set = training[inTrain,]
testing.set = training[-inTrain,]
?order
?arrange
importance.df
?head
?top_n
View(testing)
names(testing)
